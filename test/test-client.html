<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AI Voice Calling Test Client</title>
  <style>
    * { box-sizing: border-box; }
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      max-width: 900px;
      margin: 0 auto;
      padding: 20px;
      background: #f5f5f5;
    }
    h1 { color: #333; }
    .card {
      background: white;
      border-radius: 8px;
      padding: 20px;
      margin-bottom: 20px;
      box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .status {
      padding: 10px 15px;
      border-radius: 4px;
      margin-bottom: 15px;
      font-weight: 500;
    }
    .status.connected { background: #d4edda; color: #155724; }
    .status.disconnected { background: #f8d7da; color: #721c24; }
    .status.session { background: #cce5ff; color: #004085; }
    
    label { display: block; margin-bottom: 5px; font-weight: 500; }
    input, textarea, select {
      width: 100%;
      padding: 10px;
      margin-bottom: 15px;
      border: 1px solid #ddd;
      border-radius: 4px;
      font-size: 14px;
    }
    textarea { height: 100px; font-family: inherit; }
    
    button {
      padding: 12px 24px;
      border: none;
      border-radius: 4px;
      cursor: pointer;
      font-size: 14px;
      font-weight: 500;
      margin-right: 10px;
      margin-bottom: 10px;
    }
    button.primary { background: #007bff; color: white; }
    button.success { background: #28a745; color: white; }
    button.danger { background: #dc3545; color: white; }
    button.warning { background: #ffc107; color: #333; }
    button:disabled { opacity: 0.5; cursor: not-allowed; }
    
    .log-container {
      background: #1e1e1e;
      color: #d4d4d4;
      padding: 15px;
      border-radius: 4px;
      height: 300px;
      overflow-y: auto;
      font-family: 'Consolas', 'Monaco', monospace;
      font-size: 13px;
    }
    .log-entry { margin: 3px 0; }
    .log-entry.info { color: #569cd6; }
    .log-entry.success { color: #4ec9b0; }
    .log-entry.error { color: #f14c4c; }
    .log-entry.stt { color: #dcdcaa; }
    .log-entry.llm { color: #ce9178; }
    .log-entry.audio { color: #b5cea8; }
    
    .audio-controls {
      display: flex;
      align-items: center;
      gap: 15px;
      flex-wrap: wrap;
    }
    .audio-indicator {
      width: 15px;
      height: 15px;
      border-radius: 50%;
      background: #ccc;
    }
    .audio-indicator.recording { background: #dc3545; animation: pulse 1s infinite; }
    .audio-indicator.playing { background: #28a745; animation: pulse 1s infinite; }
    @keyframes pulse {
      0%, 100% { opacity: 1; }
      50% { opacity: 0.5; }
    }
    
    .row { display: flex; gap: 15px; }
    .row > * { flex: 1; }
    
    .transcript-box {
      background: #f8f9fa;
      border: 1px solid #ddd;
      border-radius: 4px;
      padding: 15px;
      min-height: 100px;
      margin-bottom: 15px;
    }
    .transcript-box h4 { margin: 0 0 10px 0; color: #666; }
    .transcript-box p { margin: 5px 0; }
    .partial { color: #888; font-style: italic; }
    .final { color: #333; }
  </style>
</head>
<body>
  <h1>üéôÔ∏è AI Voice Calling Test Client</h1>
  
  <!-- Connection Status -->
  <div id="status" class="status disconnected">Disconnected</div>
  
  <!-- Configuration -->
  <div class="card">
    <h3>Configuration</h3>
    <div class="row">
      <div>
        <label>Server URL</label>
        <input type="text" id="serverUrl" value="ws://localhost:3000" />
      </div>
      <div>
        <label>Language</label>
        <select id="language">
          <option value="hi-IN">Hindi (hi-IN)</option>
          <option value="en-IN">English India (en-IN)</option>
          <option value="ta-IN">Tamil (ta-IN)</option>
          <option value="te-IN">Telugu (te-IN)</option>
          <option value="bn-IN">Bengali (bn-IN)</option>
          <option value="mr-IN">Marathi (mr-IN)</option>
          <option value="gu-IN">Gujarati (gu-IN)</option>
        </select>
      </div>
    </div>
    
    <div class="row">
      <div>
        <label>Sarvam API Key (STT)</label>
        <input type="password" id="sarvamKey" placeholder="sk_..." />
      </div>
      <div>
        <label>Gemini API Key (LLM)</label>
        <input type="password" id="geminiKey" placeholder="AIza..." />
      </div>
    </div>
    
    <div class="row">
      <div>
        <label>TTS Provider</label>
        <select id="ttsProvider">
          <option value="sarvam">Sarvam (Bulbul v2)</option>
          <option value="cartesia">Cartesia (Sonic 3)</option>
        </select>
      </div>
      <div>
        <label>Audio Quality</label>
        <select id="audioQuality">
          <option value="web">Web (44.1kHz CD quality)</option>
          <option value="telephony">Telephony (8kHz phone)</option>
        </select>
      </div>
    </div>
    
    <div class="row">
      <div>
        <label>Cartesia API Key</label>
        <input type="password" id="cartesiaKey" placeholder="sk_cart_..." onchange="onCartesiaKeyChange()" />
      </div>
      <div>
        <label>Cartesia Voice</label>
        <select id="cartesiaVoice" disabled>
          <option value="">Enter API key to load voices</option>
        </select>
        <button type="button" onclick="loadCartesiaVoices()" style="margin-top: 5px; padding: 5px 10px; font-size: 12px;">üîÑ Load Voices</button>
      </div>
    </div>
    
    <label>System Prompt</label>
    <textarea id="systemPrompt">You are a helpful AI assistant for customer service. Respond naturally and helpfully in the same language the customer speaks. Keep responses concise and conversational.</textarea>
    
    <button class="primary" id="connectBtn" onclick="connect()">Connect</button>
    <button class="danger" id="disconnectBtn" onclick="disconnect()" disabled>Disconnect</button>
  </div>
  
  <!-- MCP / n8n Tools Configuration -->
  <div class="card">
    <h3>üîß MCP Tools (n8n Workflows)</h3>
    <div class="row">
      <div>
        <label>n8n MCP Server URL</label>
        <input type="text" id="mcpServerUrl" placeholder="http://localhost:5678/mcp" />
      </div>
      <div>
        <label>n8n API Key (optional)</label>
        <input type="password" id="mcpApiKey" placeholder="n8n API key..." />
      </div>
    </div>
    <div style="margin-top: 10px;">
      <button type="button" onclick="connectMCPServer()" id="mcpConnectBtn" disabled>üîå Connect to n8n</button>
      <button type="button" onclick="disconnectMCPServer()" id="mcpDisconnectBtn" disabled style="margin-left: 5px;">‚ùå Disconnect</button>
      <button type="button" onclick="listTools()" id="listToolsBtn" disabled style="margin-left: 5px;">üìã List Tools</button>
    </div>
    <div id="mcpStatus" style="margin-top: 10px; font-size: 12px; color: #666;">Not connected to MCP server</div>
    <div id="toolsList" style="margin-top: 10px; max-height: 150px; overflow-y: auto; font-size: 12px;"></div>
  </div>
  
  <!-- Session Controls -->
  <div class="card">
    <h3>Session Controls</h3>
    <button class="success" id="startSessionBtn" onclick="startSession()" disabled>Start Voice Session</button>
    <button class="danger" id="endSessionBtn" onclick="endSession()" disabled>End Session</button>
    
    <div class="audio-controls" style="margin-top: 15px;">
      <button class="warning" id="recordBtn" onclick="toggleConversation()" disabled>üé§ Start Conversation</button>
      <div class="audio-indicator" id="audioIndicator"></div>
      <span id="audioStatus">Not recording</span>
    </div>
  </div>
  
  <!-- Transcripts -->
  <div class="card">
    <h3>Conversation</h3>
    <div class="transcript-box">
      <h4>You (Speech-to-Text)</h4>
      <p id="userTranscript" class="partial">-</p>
    </div>
    <div class="transcript-box">
      <h4>AI Response</h4>
      <p id="aiResponse">-</p>
    </div>
  </div>
  
  <!-- Logs -->
  <div class="card">
    <h3>Event Log</h3>
    <div class="log-container" id="logContainer"></div>
    <button onclick="clearLogs()" style="margin-top: 10px;">Clear Logs</button>
  </div>
  
  <!-- Audio playback element -->
  <audio id="audioPlayer" style="display: none;"></audio>

  <script>
    let ws = null;
    let sessionId = null;
    let mediaRecorder = null;
    let audioContext = null;
    let isRecording = false;
    let audioChunks = [];
    
    // Audio playback queue to prevent chunks from overwriting each other
    let audioQueue = [];
    let isPlayingAudio = false;
    
    // Continuous conversation mode
    let isConversationActive = false;
    let audioStream = null;
    let scriptProcessor = null;
    const VAD_THRESHOLD = 0.04;  // Voice activity detection threshold (higher = less sensitive)
    let isSpeaking = false;
    let silenceStart = null;
    const SILENCE_TIMEOUT = 1500;  // ms of silence before considering speech ended
    
    // Cartesia voices cache
    let cartesiaVoices = [];
    
    async function loadCartesiaVoices() {
      const apiKey = document.getElementById('cartesiaKey').value;
      if (!apiKey) {
        log('Please enter Cartesia API key first', 'error');
        return;
      }
      
      const voiceSelect = document.getElementById('cartesiaVoice');
      voiceSelect.innerHTML = '<option value="">Loading voices...</option>';
      
      try {
        const response = await fetch('https://api.cartesia.ai/voices?limit=100', {
          method: 'GET',
          headers: {
            'X-API-Key': apiKey,
            'Cartesia-Version': '2025-04-16'
          }
        });
        
        if (!response.ok) {
          throw new Error(`API error: ${response.status}`);
        }
        
        const data = await response.json();
        cartesiaVoices = data.data || [];
        
        voiceSelect.innerHTML = '';
        voiceSelect.disabled = false;
        
        // Group voices by gender for easier selection
        const grouped = { masculine: [], feminine: [], neutral: [] };
        cartesiaVoices.forEach(voice => {
          const gender = voice.gender || 'neutral';
          if (!grouped[gender]) grouped[gender] = [];
          grouped[gender].push(voice);
        });
        
        // Add grouped options
        Object.entries(grouped).forEach(([gender, voices]) => {
          if (voices.length > 0) {
            const optgroup = document.createElement('optgroup');
            optgroup.label = gender.charAt(0).toUpperCase() + gender.slice(1);
            voices.forEach(voice => {
              const option = document.createElement('option');
              option.value = voice.id;
              option.textContent = `${voice.name} (${voice.language})`;
              option.title = voice.description || '';
              optgroup.appendChild(option);
            });
            voiceSelect.appendChild(optgroup);
          }
        });
        
        // Try to restore saved voice
        const savedVoice = localStorage.getItem('cartesiaVoice');
        if (savedVoice && cartesiaVoices.find(v => v.id === savedVoice)) {
          voiceSelect.value = savedVoice;
        }
        
        log(`Loaded ${cartesiaVoices.length} Cartesia voices`, 'success');
      } catch (error) {
        log(`Failed to load Cartesia voices: ${error.message}`, 'error');
        voiceSelect.innerHTML = '<option value="">Failed to load voices</option>';
      }
    }
    
    function onCartesiaKeyChange() {
      localStorage.setItem('cartesiaKey', document.getElementById('cartesiaKey').value);
      // Auto-load voices when key is entered
      if (document.getElementById('cartesiaKey').value) {
        loadCartesiaVoices();
      }
    }
    
    // MCP / n8n Tools Management
    let mcpConnected = false;
    let mcpServerName = null;
    
    function connectMCPServer() {
      if (!ws || ws.readyState !== WebSocket.OPEN) {
        log('Connect to server first', 'error');
        return;
      }
      
      const url = document.getElementById('mcpServerUrl').value;
      const apiKey = document.getElementById('mcpApiKey').value;
      
      if (!url) {
        log('Please enter MCP server URL', 'error');
        return;
      }
      
      mcpServerName = 'n8n-' + Date.now();
      
      ws.send(JSON.stringify({
        type: 'add_mcp_server',
        name: mcpServerName,
        transport: 'sse',  // Default to SSE for n8n MCP
        url: url,
        apiKey: apiKey || undefined
      }));
      
      document.getElementById('mcpStatus').textContent = 'Connecting to MCP server...';
      log(`Connecting to MCP server: ${url}`, 'info');
      
      // Save to localStorage
      localStorage.setItem('mcpServerUrl', url);
      if (apiKey) localStorage.setItem('mcpApiKey', apiKey);
    }
    
    function disconnectMCPServer() {
      if (!ws || ws.readyState !== WebSocket.OPEN || !mcpServerName) {
        return;
      }
      
      ws.send(JSON.stringify({
        type: 'remove_mcp_server',
        name: mcpServerName
      }));
      
      mcpConnected = false;
      mcpServerName = null;
      updateMCPUI();
      document.getElementById('mcpStatus').textContent = 'Disconnected from MCP server';
      document.getElementById('toolsList').innerHTML = '';
      log('Disconnected from MCP server', 'info');
    }
    
    function listTools() {
      if (!ws || ws.readyState !== WebSocket.OPEN) {
        log('Connect to server first', 'error');
        return;
      }
      
      ws.send(JSON.stringify({ type: 'list_tools' }));
      log('Requesting tools list...', 'info');
    }
    
    function updateMCPUI() {
      document.getElementById('mcpConnectBtn').disabled = !ws || ws.readyState !== WebSocket.OPEN || mcpConnected;
      document.getElementById('mcpDisconnectBtn').disabled = !mcpConnected;
      document.getElementById('listToolsBtn').disabled = !ws || ws.readyState !== WebSocket.OPEN;
    }
    
    function handleMCPMessage(message) {
      switch (message.type) {
        case 'mcp_server_added':
          mcpConnected = true;
          updateMCPUI();
          document.getElementById('mcpStatus').textContent = `‚úÖ Connected to: ${message.name}`;
          log(`Connected to MCP server: ${message.name}`, 'success');
          
          // Display discovered tools
          if (message.tools && message.tools.length > 0) {
            const toolsList = document.getElementById('toolsList');
            toolsList.innerHTML = '<strong>Discovered Tools:</strong><br>' + 
              message.tools.map(t => `‚Ä¢ <b>${t.name}</b>: ${t.description || 'No description'}`).join('<br>');
            log(`Discovered ${message.tools.length} tools from MCP server`, 'success');
          }
          break;
          
        case 'mcp_server_removed':
          mcpConnected = false;
          mcpServerName = null;
          updateMCPUI();
          document.getElementById('mcpStatus').textContent = 'Disconnected';
          break;
          
        case 'mcp_error':
          log(`MCP Error: ${message.error}`, 'error');
          document.getElementById('mcpStatus').textContent = `‚ùå Error: ${message.error}`;
          break;
          
        case 'tools_list':
          const toolsList = document.getElementById('toolsList');
          if (message.tools && message.tools.length > 0) {
            toolsList.innerHTML = '<strong>Available Tools:</strong><br>' + 
              message.tools.map(t => `‚Ä¢ <b>${t.name}</b>: ${t.description || 'No description'}`).join('<br>');
            log(`Listed ${message.tools.length} available tools`, 'info');
          } else {
            toolsList.innerHTML = '<em>No tools registered</em>';
          }
          break;
      }
    }
    
    function log(message, type = 'info') {
      const container = document.getElementById('logContainer');
      const entry = document.createElement('div');
      entry.className = `log-entry ${type}`;
      entry.textContent = `[${new Date().toLocaleTimeString()}] ${message}`;
      container.appendChild(entry);
      container.scrollTop = container.scrollHeight;
    }
    
    function clearLogs() {
      document.getElementById('logContainer').innerHTML = '';
    }
    
    function updateStatus(text, className) {
      const status = document.getElementById('status');
      status.textContent = text;
      status.className = `status ${className}`;
    }
    
    function connect() {
      const url = document.getElementById('serverUrl').value;
      log(`Connecting to ${url}...`);
      
      ws = new WebSocket(url);
      
      ws.onopen = () => {
        log('WebSocket connected', 'success');
        updateStatus('Connected', 'connected');
        document.getElementById('connectBtn').disabled = true;
        document.getElementById('disconnectBtn').disabled = false;
        document.getElementById('startSessionBtn').disabled = false;
        updateMCPUI();  // Enable MCP buttons
      };
      
      ws.onclose = () => {
        log('WebSocket disconnected', 'error');
        updateStatus('Disconnected', 'disconnected');
        document.getElementById('connectBtn').disabled = false;
        document.getElementById('disconnectBtn').disabled = true;
        document.getElementById('startSessionBtn').disabled = true;
        document.getElementById('endSessionBtn').disabled = true;
        document.getElementById('recordBtn').disabled = true;
        sessionId = null;
        mcpConnected = false;
        mcpServerName = null;
        updateMCPUI();  // Reset MCP UI
      };
      
      ws.onerror = (err) => {
        log(`WebSocket error: ${err.message || 'Unknown error'}`, 'error');
      };
      
      ws.onmessage = (event) => {
        if (event.data instanceof Blob) {
          // Binary audio data from TTS
          handleAudioData(event.data);
          return;
        }
        
        try {
          const msg = JSON.parse(event.data);
          handleMessage(msg);
        } catch (e) {
          log(`Failed to parse message: ${e.message}`, 'error');
        }
      };
    }
    
    function disconnect() {
      if (ws) {
        ws.close();
        ws = null;
      }
    }
    
    function startSession() {
      const ttsProvider = document.getElementById('ttsProvider').value;
      const cartesiaKey = document.getElementById('cartesiaKey').value;
      const sarvamKey = document.getElementById('sarvamKey').value;
      const audioQuality = document.getElementById('audioQuality').value;
      const cartesiaVoice = document.getElementById('cartesiaVoice').value;
      
      // Determine TTS config based on selected provider
      let ttsConfig;
      if (ttsProvider === 'cartesia') {
        const voiceId = cartesiaVoice || 'f786b574-daa5-4673-aa0c-cbe3e8534c02';  // Default to Katie
        ttsConfig = {
          provider: 'cartesia',
          apiKey: cartesiaKey,
          voiceId: voiceId,
          audioQuality: audioQuality  // 'web' or 'telephony'
        };
        // Save selected voice
        localStorage.setItem('cartesiaVoice', voiceId);
      } else {
        ttsConfig = {
          provider: 'sarvam',
          apiKey: sarvamKey,
          voiceId: 'anushka'
        };
      }
      
      const config = {
        type: 'start_session',
        tenantId: 'test-client',
        config: {
          language: document.getElementById('language').value,
          systemPrompt: document.getElementById('systemPrompt').value,
          stt: {
            provider: 'sarvam',
            apiKey: sarvamKey
          },
          llm: {
            provider: 'gemini',
            apiKey: document.getElementById('geminiKey').value,
            model: 'gemini-2.5-flash'
          },
          tts: ttsConfig
        }
      };
      
      log(`Starting voice session with ${ttsProvider} TTS...`, 'info');
      ws.send(JSON.stringify(config));
    }
    
    function endSession() {
      if (sessionId && ws) {
        ws.send(JSON.stringify({
          type: 'end_session',
          sessionId: sessionId
        }));
        log('Ending session...', 'info');
      }
    }
    
    function handleMessage(msg) {
      switch (msg.type) {
        case 'connected':
          log(`Connection ID: ${msg.connectionId}`, 'success');
          break;
          
        case 'session_started':
          sessionId = msg.sessionId;
          log(`Session started: ${sessionId}`, 'success');
          // Configure audio player with server's audio format
          if (msg.audioFormat) {
            serverSampleRate = msg.audioFormat.sampleRate || 44100;
            log(`Audio format: ${serverSampleRate}Hz, ${msg.audioFormat.bitsPerSample}-bit, ${msg.audioFormat.encoding}`, 'info');
          }
          updateStatus(`Session: ${sessionId.substring(0, 8)}...`, 'session');
          document.getElementById('startSessionBtn').disabled = true;
          document.getElementById('endSessionBtn').disabled = false;
          document.getElementById('recordBtn').disabled = false;
          break;
          
        case 'session_ended':
          log(`Session ended. Metrics: ${JSON.stringify(msg.metrics)}`, 'info');
          sessionId = null;
          updateStatus('Connected (No Session)', 'connected');
          document.getElementById('startSessionBtn').disabled = false;
          document.getElementById('endSessionBtn').disabled = true;
          document.getElementById('recordBtn').disabled = true;
          break;
          
        case 'stt_partial':
          log(`STT Partial: ${msg.text}`, 'stt');
          document.getElementById('userTranscript').textContent = msg.text;
          document.getElementById('userTranscript').className = 'partial';
          break;
          
        case 'stt_final':
          log(`STT Final: ${msg.text}`, 'stt');
          document.getElementById('userTranscript').textContent = msg.text;
          document.getElementById('userTranscript').className = 'final';
          break;
          
        case 'llm_token':
          // Append token to response
          const responseEl = document.getElementById('aiResponse');
          if (responseEl.textContent === '-') responseEl.textContent = '';
          responseEl.textContent += msg.token;
          break;
          
        case 'llm_sentence':
          log(`LLM Sentence: ${msg.sentence}`, 'llm');
          break;
        
        case 'first_audio_byte':
          log(`‚ö° First audio byte: ${msg.latencyMs}ms`, 'success');
          break;
          
        case 'turn_complete':
          const m = msg.metrics || {};
          log(`Turn complete. First LLM: ${m.firstLLMTokenMs || 0}ms, First Audio: ${m.firstTTSByteMs || 0}ms, Total: ${m.turnDurationMs || 0}ms`, 'success');
          break;
          
        case 'barge_in':
          log('Barge-in detected - stopping playback', 'info');
          break;
          
        case 'error':
          log(`Error: ${msg.error}`, 'error');
          break;
        
        // MCP messages
        case 'mcp_server_added':
        case 'mcp_server_removed':
        case 'mcp_error':
        case 'tools_list':
          handleMCPMessage(msg);
          break;
          
        default:
          log(`Unknown message: ${JSON.stringify(msg)}`, 'info');
      }
    }
    
    // ========================================
    // AUDIOWORKLET-BASED PCM STREAMING PLAYER
    // Ring buffer architecture for zero-crackle playback
    // Audio thread pulls samples at constant rate
    // Main thread only enqueues - never schedules
    // ========================================
    
    let playbackAudioContext = null;
    let pcmWorkletNode = null;
    let isProcessingAudio = false;
    let serverSampleRate = 44100;
    let workletReady = false;
    let workletInitializing = false;  // Prevent race condition
    
    // AudioWorklet processor code (embedded as blob)
    const workletCode = `
      class PCMStreamProcessor extends AudioWorkletProcessor {
        constructor() {
          super();
          // Ring buffer: 15 seconds at 44.1kHz = 661500 samples
          // TTS generates faster than real-time, so we need a large buffer
          this.bufferSize = 661500;
          this.buffer = new Float32Array(this.bufferSize);
          this.writeIndex = 0;
          this.readIndex = 0;
          this.samplesAvailable = 0;
          
          this.port.onmessage = (e) => {
            if (e.data.type === 'samples') {
              this.enqueueSamples(e.data.samples);
            } else if (e.data.type === 'clear') {
              this.clearBuffer();
            }
          };
        }
        
        enqueueSamples(samples) {
          for (let i = 0; i < samples.length; i++) {
            this.buffer[this.writeIndex] = samples[i];
            this.writeIndex = (this.writeIndex + 1) % this.bufferSize;
            
            // If we overflow, advance read pointer (drop old samples)
            if (this.samplesAvailable >= this.bufferSize) {
              this.readIndex = (this.readIndex + 1) % this.bufferSize;
            } else {
              this.samplesAvailable++;
            }
          }
        }
        
        clearBuffer() {
          this.writeIndex = 0;
          this.readIndex = 0;
          this.samplesAvailable = 0;
          this.buffer.fill(0);
        }
        
        process(inputs, outputs, parameters) {
          const output = outputs[0];
          const channel = output[0];
          
          for (let i = 0; i < channel.length; i++) {
            if (this.samplesAvailable > 0) {
              channel[i] = this.buffer[this.readIndex];
              this.readIndex = (this.readIndex + 1) % this.bufferSize;
              this.samplesAvailable--;
            } else {
              // Underrun: output silence
              channel[i] = 0;
            }
          }
          
          // Report buffer status periodically
          if (Math.random() < 0.01) {
            this.port.postMessage({
              type: 'status',
              samplesAvailable: this.samplesAvailable,
              bufferMs: Math.round(this.samplesAvailable / sampleRate * 1000)
            });
          }
          
          return true; // Keep processor alive
        }
      }
      
      registerProcessor('pcm-stream-processor', PCMStreamProcessor);
    `;
    
    async function initAudioWorklet() {
      // Prevent multiple simultaneous init attempts
      if (workletReady || workletInitializing) return;
      workletInitializing = true;
      
      try {
        playbackAudioContext = new (window.AudioContext || window.webkitAudioContext)({
          sampleRate: serverSampleRate
        });
        
        // Create blob URL for worklet code
        const blob = new Blob([workletCode], { type: 'application/javascript' });
        const workletUrl = URL.createObjectURL(blob);
        
        await playbackAudioContext.audioWorklet.addModule(workletUrl);
        URL.revokeObjectURL(workletUrl);
        
        pcmWorkletNode = new AudioWorkletNode(playbackAudioContext, 'pcm-stream-processor');
        pcmWorkletNode.connect(playbackAudioContext.destination);
        
        // Handle status messages from worklet
        pcmWorkletNode.port.onmessage = (e) => {
          if (e.data.type === 'status') {
            const bufferMs = e.data.bufferMs;
            if (bufferMs > 0) {
              isPlayingAudio = true;
              document.getElementById('audioIndicator').classList.add('playing');
              document.getElementById('audioStatus').textContent = `Playing... (${bufferMs}ms buffered)`;
            } else {
              isPlayingAudio = false;
              document.getElementById('audioIndicator').classList.remove('playing');
              document.getElementById('audioStatus').textContent = isConversationActive ? 'Listening...' : 'Ready';
            }
          }
        };
        
        workletReady = true;
        log(`AudioWorklet initialized at ${serverSampleRate}Hz`, 'info');
        
      } catch (e) {
        log(`AudioWorklet init failed: ${e.message}, falling back to ScriptProcessor`, 'error');
        initScriptProcessorFallback();
      }
    }
    
    // Fallback for browsers without AudioWorklet support
    // Buffer size: 15 seconds at 44.1kHz = 661500 samples
    const FALLBACK_BUFFER_SIZE = 661500;
    let fallbackScriptNode = null;
    let fallbackBuffer = new Float32Array(FALLBACK_BUFFER_SIZE);
    let fallbackWriteIdx = 0;
    let fallbackReadIdx = 0;
    let fallbackSamplesAvail = 0;
    
    function initScriptProcessorFallback() {
      // Prevent multiple fallback inits
      if (fallbackScriptNode) return;
      
      if (!playbackAudioContext) {
        playbackAudioContext = new (window.AudioContext || window.webkitAudioContext)({
          sampleRate: serverSampleRate
        });
      }
      
      fallbackScriptNode = playbackAudioContext.createScriptProcessor(2048, 1, 1);
      fallbackScriptNode.onaudioprocess = (e) => {
        const output = e.outputBuffer.getChannelData(0);
        for (let i = 0; i < output.length; i++) {
          if (fallbackSamplesAvail > 0) {
            output[i] = fallbackBuffer[fallbackReadIdx];
            fallbackReadIdx = (fallbackReadIdx + 1) % FALLBACK_BUFFER_SIZE;
            fallbackSamplesAvail--;
          } else {
            output[i] = 0;
          }
        }
        
        // Update UI periodically (not every frame)
        if (Math.random() < 0.05) {
          if (fallbackSamplesAvail > 0) {
            isPlayingAudio = true;
            document.getElementById('audioIndicator').classList.add('playing');
            const bufferMs = Math.round(fallbackSamplesAvail / serverSampleRate * 1000);
            document.getElementById('audioStatus').textContent = `Playing... (${bufferMs}ms buffered)`;
          } else if (isPlayingAudio) {
            isPlayingAudio = false;
            document.getElementById('audioIndicator').classList.remove('playing');
            document.getElementById('audioStatus').textContent = isConversationActive ? 'Listening...' : 'Ready';
          }
        }
      };
      fallbackScriptNode.connect(playbackAudioContext.destination);
      workletReady = true;
      log(`ScriptProcessor fallback initialized at ${serverSampleRate}Hz`, 'info');
    }
    
    function enqueuePCMSamples(float32Samples) {
      if (pcmWorkletNode) {
        // Send to AudioWorklet
        pcmWorkletNode.port.postMessage({ type: 'samples', samples: float32Samples });
      } else if (fallbackScriptNode) {
        // Fallback: enqueue directly
        for (let i = 0; i < float32Samples.length; i++) {
          fallbackBuffer[fallbackWriteIdx] = float32Samples[i];
          fallbackWriteIdx = (fallbackWriteIdx + 1) % FALLBACK_BUFFER_SIZE;
          if (fallbackSamplesAvail < FALLBACK_BUFFER_SIZE) fallbackSamplesAvail++;
        }
      }
    }
    
    async function handleAudioData(blob) {
      log(`Received audio chunk: ${blob.size} bytes`, 'audio');
      
      // Don't play if user is speaking (barge-in)
      if (isSpeaking) {
        return;
      }
      
      // Initialize on first audio
      if (!workletReady) {
        await initAudioWorklet();
      }
      
      // Resume if suspended
      if (playbackAudioContext && playbackAudioContext.state === 'suspended') {
        await playbackAudioContext.resume();
      }
      
      try {
        const arrayBuffer = await blob.arrayBuffer();
        let pcmData = arrayBuffer;
        
        // Check if this is a WAV file (starts with "RIFF")
        const header = new Uint8Array(arrayBuffer.slice(0, 4));
        const isWav = header[0] === 0x52 && header[1] === 0x49 && header[2] === 0x46 && header[3] === 0x46; // "RIFF"
        
        if (isWav) {
          // Strip 44-byte WAV header to get raw PCM
          pcmData = arrayBuffer.slice(44);
        }
        
        // Ensure byte length is multiple of 2 for Int16Array
        if (pcmData.byteLength % 2 !== 0) {
          pcmData = pcmData.slice(0, pcmData.byteLength - 1);
        }
        
        const int16Array = new Int16Array(pcmData);
        
        // Convert Int16 PCM to Float32 [-1, 1]
        const float32Samples = new Float32Array(int16Array.length);
        for (let i = 0; i < int16Array.length; i++) {
          float32Samples[i] = int16Array[i] / 32768.0;
        }
        
        // Enqueue to ring buffer (audio thread will pull)
        enqueuePCMSamples(float32Samples);
        
        isPlayingAudio = true;
        isProcessingAudio = true;
        
      } catch (e) {
        log(`PCM processing error: ${e.message}`, 'error');
      }
    }
    
    function processAudioQueue() {
      // Not needed - audio thread pulls from ring buffer
    }
    
    function tryPlayAudio() {
      // Not needed - audio thread pulls from ring buffer
    }
    
    async function playNextAudioChunk() {
      // Not needed - audio thread pulls from ring buffer
    }
    
    function clearAudioQueue() {
      // Clear ring buffer immediately (barge-in)
      if (pcmWorkletNode) {
        pcmWorkletNode.port.postMessage({ type: 'clear' });
      }
      
      // Clear fallback buffer
      fallbackWriteIdx = 0;
      fallbackReadIdx = 0;
      fallbackSamplesAvail = 0;
      
      isPlayingAudio = false;
      isProcessingAudio = false;
      
      // Legacy cleanup
      audioQueue.forEach(url => URL.revokeObjectURL(url));
      audioQueue = [];
      
      document.getElementById('audioIndicator').classList.remove('playing');
      document.getElementById('audioStatus').textContent = isConversationActive ? 'Listening...' : 'Ready';
    }
    
    async function toggleConversation() {
      if (isConversationActive) {
        stopConversation();
      } else {
        await startConversation();
      }
    }
    
    async function startConversation() {
      if (isConversationActive) return;
      
      try {
        audioStream = await navigator.mediaDevices.getUserMedia({ 
          audio: {
            sampleRate: 16000,
            channelCount: 1,
            echoCancellation: true,
            noiseSuppression: true
          }
        });
        
        audioContext = new AudioContext({ sampleRate: 16000 });
        const source = audioContext.createMediaStreamSource(audioStream);
        scriptProcessor = audioContext.createScriptProcessor(4096, 1, 1);
        
        scriptProcessor.onaudioprocess = (e) => {
          if (!isConversationActive || !ws || ws.readyState !== WebSocket.OPEN) return;
          
          const inputData = e.inputBuffer.getChannelData(0);
          
          // Calculate audio level for VAD
          let sum = 0;
          for (let i = 0; i < inputData.length; i++) {
            sum += inputData[i] * inputData[i];
          }
          const rms = Math.sqrt(sum / inputData.length);
          
          // Voice Activity Detection
          if (rms > VAD_THRESHOLD) {
            // User is speaking
            if (!isSpeaking) {
              isSpeaking = true;
              log('Voice detected', 'info');
              
              // Barge-in: stop AI audio if playing
              if (isPlayingAudio || audioQueue.length > 0) {
                log('Barge-in: stopping AI audio', 'info');
                clearAudioQueue();
                
                // Notify server to abort current turn
                if (ws && ws.readyState === WebSocket.OPEN && sessionId) {
                  ws.send(JSON.stringify({ type: 'barge_in', sessionId }));
                }
              }
            }
            silenceStart = null;
          } else {
            // Silence detected
            if (isSpeaking) {
              if (!silenceStart) {
                silenceStart = Date.now();
              } else if (Date.now() - silenceStart > SILENCE_TIMEOUT) {
                isSpeaking = false;
                log('Speech ended (silence detected)', 'info');
                
                // Try to play any queued audio now that user stopped speaking
                if (audioQueue.length > 0 && !isPlayingAudio) {
                  tryPlayAudio();
                }
              }
            }
          }
          
          // Always send audio to server (server does its own VAD)
          const pcmData = new Int16Array(inputData.length);
          for (let i = 0; i < inputData.length; i++) {
            pcmData[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
          }
          ws.send(pcmData.buffer);
        };
        
        source.connect(scriptProcessor);
        scriptProcessor.connect(audioContext.destination);
        
        isConversationActive = true;
        isRecording = true;
        document.getElementById('recordBtn').textContent = 'üî¥ End Conversation';
        document.getElementById('recordBtn').classList.remove('warning');
        document.getElementById('recordBtn').classList.add('danger');
        document.getElementById('audioIndicator').classList.add('recording');
        document.getElementById('audioStatus').textContent = 'Listening...';
        document.getElementById('aiResponse').textContent = '-';
        
        log('Conversation started - speak anytime', 'success');
        
      } catch (err) {
        log(`Microphone error: ${err.message}`, 'error');
      }
    }
    
    function stopConversation() {
      if (!isConversationActive) return;
      
      isConversationActive = false;
      isRecording = false;
      isSpeaking = false;
      
      if (scriptProcessor) {
        scriptProcessor.disconnect();
        scriptProcessor = null;
      }
      
      if (audioContext) {
        audioContext.close();
        audioContext = null;
      }
      
      if (audioStream) {
        audioStream.getTracks().forEach(track => track.stop());
        audioStream = null;
      }
      
      clearAudioQueue();
      
      document.getElementById('recordBtn').textContent = 'üé§ Start Conversation';
      document.getElementById('recordBtn').classList.remove('danger');
      document.getElementById('recordBtn').classList.add('warning');
      document.getElementById('audioIndicator').classList.remove('recording');
      document.getElementById('audioStatus').textContent = 'Conversation ended';
      
      log('Conversation ended', 'info');
    }
    
    // Load saved settings from localStorage
    document.addEventListener('DOMContentLoaded', () => {
      const savedSarvam = localStorage.getItem('sarvamKey');
      const savedGemini = localStorage.getItem('geminiKey');
      const savedCartesia = localStorage.getItem('cartesiaKey');
      const savedTtsProvider = localStorage.getItem('ttsProvider');
      const savedAudioQuality = localStorage.getItem('audioQuality');
      const savedMcpUrl = localStorage.getItem('mcpServerUrl');
      const savedMcpApiKey = localStorage.getItem('mcpApiKey');
      
      if (savedSarvam) document.getElementById('sarvamKey').value = savedSarvam;
      if (savedGemini) document.getElementById('geminiKey').value = savedGemini;
      if (savedCartesia) document.getElementById('cartesiaKey').value = savedCartesia;
      if (savedTtsProvider) document.getElementById('ttsProvider').value = savedTtsProvider;
      if (savedAudioQuality) document.getElementById('audioQuality').value = savedAudioQuality;
      if (savedMcpUrl) document.getElementById('mcpServerUrl').value = savedMcpUrl;
      if (savedMcpApiKey) document.getElementById('mcpApiKey').value = savedMcpApiKey;
      
      // Auto-load Cartesia voices if API key is saved
      if (savedCartesia) {
        loadCartesiaVoices();
      }
    });
    
    // Save settings when changed
    document.getElementById('sarvamKey').addEventListener('change', (e) => {
      localStorage.setItem('sarvamKey', e.target.value);
    });
    document.getElementById('geminiKey').addEventListener('change', (e) => {
      localStorage.setItem('geminiKey', e.target.value);
    });
    document.getElementById('audioQuality').addEventListener('change', (e) => {
      localStorage.setItem('audioQuality', e.target.value);
    });
    document.getElementById('ttsProvider').addEventListener('change', (e) => {
      localStorage.setItem('ttsProvider', e.target.value);
    });
  </script>
</body>
</html>
